{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML-AZ-Sec21-DecisionTree.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_LulNCC8z96"
      },
      "source": [
        "## Decision Tree\n",
        "\n",
        "1.   Apply the Decision Tree classification algorithm to predict a category\n",
        "\n",
        "2.   **Input** = Social_Network_Ads.csv \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpXdowrE9DxW"
      },
      "source": [
        "## Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhKd4hWx9GFt"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt       #graphs\n",
        "import pandas as pd"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31oDCD5JFvri"
      },
      "source": [
        "# Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCX22pc2F8Cz"
      },
      "source": [
        "dataset = pd.read_csv('Social_Network_Ads.csv')\n",
        "x = dataset.iloc[:, :-1].values      #There is no need to use the column Position\n",
        "y = dataset.iloc[:,-1].values\n",
        "\n"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FS_CMupdWvR"
      },
      "source": [
        "##Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6aLyW-ndVhE"
      },
      "source": [
        "# Multiple Linear Regression: Split dataset into Traning and Test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsgM4SdJi-XS"
      },
      "source": [
        "# Feature Scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytZhCHxrANrz",
        "outputId": "5f044358-26d2-47be-8bea-123bb7353e9c"
      },
      "source": [
        "print(X_train)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[    44  39000]\n",
            " [    32 120000]\n",
            " [    38  50000]\n",
            " [    32 135000]\n",
            " [    52  21000]\n",
            " [    53 104000]\n",
            " [    39  42000]\n",
            " [    38  61000]\n",
            " [    36  50000]\n",
            " [    36  63000]\n",
            " [    35  25000]\n",
            " [    35  50000]\n",
            " [    42  73000]\n",
            " [    47  49000]\n",
            " [    59  29000]\n",
            " [    49  65000]\n",
            " [    45 131000]\n",
            " [    31  89000]\n",
            " [    46  82000]\n",
            " [    47  51000]\n",
            " [    26  15000]\n",
            " [    60 102000]\n",
            " [    38 112000]\n",
            " [    40 107000]\n",
            " [    42  53000]\n",
            " [    35  59000]\n",
            " [    48  41000]\n",
            " [    48 134000]\n",
            " [    38 113000]\n",
            " [    29 148000]\n",
            " [    26  15000]\n",
            " [    60  42000]\n",
            " [    24  19000]\n",
            " [    42 149000]\n",
            " [    46  96000]\n",
            " [    28  59000]\n",
            " [    39  96000]\n",
            " [    28  89000]\n",
            " [    41  72000]\n",
            " [    45  26000]\n",
            " [    33  69000]\n",
            " [    20  82000]\n",
            " [    31  74000]\n",
            " [    42  80000]\n",
            " [    35  72000]\n",
            " [    33 149000]\n",
            " [    40  71000]\n",
            " [    51 146000]\n",
            " [    46  79000]\n",
            " [    35  75000]\n",
            " [    38  51000]\n",
            " [    36  75000]\n",
            " [    37  78000]\n",
            " [    38  61000]\n",
            " [    60 108000]\n",
            " [    20  82000]\n",
            " [    57  74000]\n",
            " [    42  65000]\n",
            " [    26  80000]\n",
            " [    46 117000]\n",
            " [    35  61000]\n",
            " [    21  68000]\n",
            " [    28  44000]\n",
            " [    41  87000]\n",
            " [    37  33000]\n",
            " [    27  90000]\n",
            " [    39  42000]\n",
            " [    28 123000]\n",
            " [    31 118000]\n",
            " [    25  87000]\n",
            " [    35  71000]\n",
            " [    37  70000]\n",
            " [    35  39000]\n",
            " [    47  23000]\n",
            " [    35 147000]\n",
            " [    48 138000]\n",
            " [    26  86000]\n",
            " [    25  79000]\n",
            " [    52 138000]\n",
            " [    51  23000]\n",
            " [    35  60000]\n",
            " [    33 113000]\n",
            " [    30 107000]\n",
            " [    48  33000]\n",
            " [    41  80000]\n",
            " [    48  96000]\n",
            " [    31  18000]\n",
            " [    31  71000]\n",
            " [    43 129000]\n",
            " [    59  76000]\n",
            " [    18  44000]\n",
            " [    36 118000]\n",
            " [    42  90000]\n",
            " [    47  30000]\n",
            " [    26  43000]\n",
            " [    40  78000]\n",
            " [    46  59000]\n",
            " [    59  42000]\n",
            " [    46  74000]\n",
            " [    35  91000]\n",
            " [    28  59000]\n",
            " [    40  57000]\n",
            " [    59 143000]\n",
            " [    57  26000]\n",
            " [    52  38000]\n",
            " [    47 113000]\n",
            " [    53 143000]\n",
            " [    35  27000]\n",
            " [    58 101000]\n",
            " [    45  45000]\n",
            " [    23  82000]\n",
            " [    46  23000]\n",
            " [    42  65000]\n",
            " [    28  84000]\n",
            " [    38  59000]\n",
            " [    26  84000]\n",
            " [    29  28000]\n",
            " [    37  71000]\n",
            " [    22  55000]\n",
            " [    48  35000]\n",
            " [    49  28000]\n",
            " [    38  65000]\n",
            " [    27  17000]\n",
            " [    46  28000]\n",
            " [    48 141000]\n",
            " [    26  17000]\n",
            " [    35  97000]\n",
            " [    39  59000]\n",
            " [    24  27000]\n",
            " [    32  18000]\n",
            " [    46  88000]\n",
            " [    35  58000]\n",
            " [    56  60000]\n",
            " [    47  34000]\n",
            " [    40  72000]\n",
            " [    32 100000]\n",
            " [    19  21000]\n",
            " [    25  90000]\n",
            " [    35  88000]\n",
            " [    28  32000]\n",
            " [    50  20000]\n",
            " [    40  59000]\n",
            " [    50  44000]\n",
            " [    35  72000]\n",
            " [    40 142000]\n",
            " [    46  32000]\n",
            " [    39  71000]\n",
            " [    20  74000]\n",
            " [    29  75000]\n",
            " [    31  76000]\n",
            " [    47  25000]\n",
            " [    40  61000]\n",
            " [    34 112000]\n",
            " [    38  80000]\n",
            " [    42  75000]\n",
            " [    47  47000]\n",
            " [    39  75000]\n",
            " [    19  25000]\n",
            " [    37  80000]\n",
            " [    36  60000]\n",
            " [    41  52000]\n",
            " [    36 125000]\n",
            " [    48  29000]\n",
            " [    36 126000]\n",
            " [    51 134000]\n",
            " [    27  57000]\n",
            " [    38  71000]\n",
            " [    39  61000]\n",
            " [    22  27000]\n",
            " [    33  60000]\n",
            " [    48  74000]\n",
            " [    58  23000]\n",
            " [    53  72000]\n",
            " [    32 117000]\n",
            " [    54  70000]\n",
            " [    30  80000]\n",
            " [    58  95000]\n",
            " [    26  52000]\n",
            " [    45  79000]\n",
            " [    24  55000]\n",
            " [    40  75000]\n",
            " [    33  28000]\n",
            " [    44 139000]\n",
            " [    22  18000]\n",
            " [    33  51000]\n",
            " [    43 133000]\n",
            " [    24  32000]\n",
            " [    46  22000]\n",
            " [    35  55000]\n",
            " [    54 104000]\n",
            " [    48 119000]\n",
            " [    35  53000]\n",
            " [    37 144000]\n",
            " [    23  66000]\n",
            " [    37 137000]\n",
            " [    31  58000]\n",
            " [    33  41000]\n",
            " [    45  22000]\n",
            " [    30  15000]\n",
            " [    19  19000]\n",
            " [    49  74000]\n",
            " [    39 122000]\n",
            " [    35  73000]\n",
            " [    39  71000]\n",
            " [    24  23000]\n",
            " [    41  72000]\n",
            " [    29  83000]\n",
            " [    54  26000]\n",
            " [    35  44000]\n",
            " [    37  75000]\n",
            " [    29  47000]\n",
            " [    31  68000]\n",
            " [    42  54000]\n",
            " [    30 135000]\n",
            " [    52 114000]\n",
            " [    50  36000]\n",
            " [    56 133000]\n",
            " [    29  61000]\n",
            " [    30  89000]\n",
            " [    26  16000]\n",
            " [    33  31000]\n",
            " [    41  72000]\n",
            " [    36  33000]\n",
            " [    55 125000]\n",
            " [    48 131000]\n",
            " [    41  71000]\n",
            " [    30  62000]\n",
            " [    37  72000]\n",
            " [    41  63000]\n",
            " [    58  47000]\n",
            " [    30 116000]\n",
            " [    20  49000]\n",
            " [    37  74000]\n",
            " [    41  59000]\n",
            " [    49  89000]\n",
            " [    28  79000]\n",
            " [    53  82000]\n",
            " [    40  57000]\n",
            " [    60  34000]\n",
            " [    35 108000]\n",
            " [    21  72000]\n",
            " [    38  71000]\n",
            " [    39 106000]\n",
            " [    37  57000]\n",
            " [    26  72000]\n",
            " [    35  23000]\n",
            " [    54 108000]\n",
            " [    30  17000]\n",
            " [    39 134000]\n",
            " [    29  43000]\n",
            " [    33  43000]\n",
            " [    35  38000]\n",
            " [    41  45000]\n",
            " [    41  72000]\n",
            " [    39 134000]\n",
            " [    27 137000]\n",
            " [    21  16000]\n",
            " [    26  32000]\n",
            " [    31  66000]\n",
            " [    39  73000]\n",
            " [    41  79000]\n",
            " [    47  50000]\n",
            " [    41  30000]\n",
            " [    37  93000]\n",
            " [    60  46000]\n",
            " [    25  22000]\n",
            " [    28  37000]\n",
            " [    38  55000]\n",
            " [    36  54000]\n",
            " [    20  36000]\n",
            " [    56 104000]\n",
            " [    40  57000]\n",
            " [    42 108000]\n",
            " [    20  23000]\n",
            " [    40  65000]\n",
            " [    47  20000]\n",
            " [    18  86000]\n",
            " [    35  79000]\n",
            " [    57  33000]\n",
            " [    34  72000]\n",
            " [    49  39000]\n",
            " [    27  31000]\n",
            " [    19  70000]\n",
            " [    39  79000]\n",
            " [    26  81000]\n",
            " [    25  80000]\n",
            " [    28  85000]\n",
            " [    55  39000]\n",
            " [    50  88000]\n",
            " [    49  88000]\n",
            " [    52 150000]\n",
            " [    35  65000]\n",
            " [    42  54000]\n",
            " [    34  43000]\n",
            " [    37  52000]\n",
            " [    48  30000]\n",
            " [    29  43000]\n",
            " [    36  52000]\n",
            " [    27  54000]\n",
            " [    26 118000]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOFbVfRW_SHf"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.fit_transform(X_test)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbWbBp15ADET",
        "outputId": "f4dcb1e6-fb02-4409-9d2f-c30f82609024"
      },
      "source": [
        "print(X_train)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.58 -0.89]\n",
            " [-0.61  1.46]\n",
            " [-0.01 -0.57]\n",
            " [-0.61  1.9 ]\n",
            " [ 1.37 -1.41]\n",
            " [ 1.47  1.  ]\n",
            " [ 0.09 -0.8 ]\n",
            " [-0.01 -0.25]\n",
            " [-0.21 -0.57]\n",
            " [-0.21 -0.19]\n",
            " [-0.31 -1.29]\n",
            " [-0.31 -0.57]\n",
            " [ 0.38  0.1 ]\n",
            " [ 0.88 -0.6 ]\n",
            " [ 2.07 -1.18]\n",
            " [ 1.08 -0.13]\n",
            " [ 0.68  1.78]\n",
            " [-0.71  0.56]\n",
            " [ 0.78  0.36]\n",
            " [ 0.88 -0.54]\n",
            " [-1.2  -1.58]\n",
            " [ 2.17  0.94]\n",
            " [-0.01  1.23]\n",
            " [ 0.19  1.08]\n",
            " [ 0.38 -0.48]\n",
            " [-0.31 -0.31]\n",
            " [ 0.98 -0.83]\n",
            " [ 0.98  1.87]\n",
            " [-0.01  1.26]\n",
            " [-0.9   2.27]\n",
            " [-1.2  -1.58]\n",
            " [ 2.17 -0.8 ]\n",
            " [-1.4  -1.47]\n",
            " [ 0.38  2.3 ]\n",
            " [ 0.78  0.77]\n",
            " [-1.   -0.31]\n",
            " [ 0.09  0.77]\n",
            " [-1.    0.56]\n",
            " [ 0.28  0.07]\n",
            " [ 0.68 -1.26]\n",
            " [-0.51 -0.02]\n",
            " [-1.8   0.36]\n",
            " [-0.71  0.13]\n",
            " [ 0.38  0.3 ]\n",
            " [-0.31  0.07]\n",
            " [-0.51  2.3 ]\n",
            " [ 0.19  0.04]\n",
            " [ 1.27  2.22]\n",
            " [ 0.78  0.27]\n",
            " [-0.31  0.16]\n",
            " [-0.01 -0.54]\n",
            " [-0.21  0.16]\n",
            " [-0.11  0.24]\n",
            " [-0.01 -0.25]\n",
            " [ 2.17  1.11]\n",
            " [-1.8   0.36]\n",
            " [ 1.87  0.13]\n",
            " [ 0.38 -0.13]\n",
            " [-1.2   0.3 ]\n",
            " [ 0.78  1.37]\n",
            " [-0.31 -0.25]\n",
            " [-1.7  -0.05]\n",
            " [-1.   -0.74]\n",
            " [ 0.28  0.5 ]\n",
            " [-0.11 -1.06]\n",
            " [-1.1   0.59]\n",
            " [ 0.09 -0.8 ]\n",
            " [-1.    1.55]\n",
            " [-0.71  1.4 ]\n",
            " [-1.3   0.5 ]\n",
            " [-0.31  0.04]\n",
            " [-0.11  0.01]\n",
            " [-0.31 -0.89]\n",
            " [ 0.88 -1.35]\n",
            " [-0.31  2.24]\n",
            " [ 0.98  1.98]\n",
            " [-1.2   0.48]\n",
            " [-1.3   0.27]\n",
            " [ 1.37  1.98]\n",
            " [ 1.27 -1.35]\n",
            " [-0.31 -0.28]\n",
            " [-0.51  1.26]\n",
            " [-0.8   1.08]\n",
            " [ 0.98 -1.06]\n",
            " [ 0.28  0.3 ]\n",
            " [ 0.98  0.77]\n",
            " [-0.71 -1.5 ]\n",
            " [-0.71  0.04]\n",
            " [ 0.48  1.72]\n",
            " [ 2.07  0.19]\n",
            " [-1.99 -0.74]\n",
            " [-0.21  1.4 ]\n",
            " [ 0.38  0.59]\n",
            " [ 0.88 -1.15]\n",
            " [-1.2  -0.77]\n",
            " [ 0.19  0.24]\n",
            " [ 0.78 -0.31]\n",
            " [ 2.07 -0.8 ]\n",
            " [ 0.78  0.13]\n",
            " [-0.31  0.62]\n",
            " [-1.   -0.31]\n",
            " [ 0.19 -0.36]\n",
            " [ 2.07  2.13]\n",
            " [ 1.87 -1.26]\n",
            " [ 1.37 -0.92]\n",
            " [ 0.88  1.26]\n",
            " [ 1.47  2.13]\n",
            " [-0.31 -1.23]\n",
            " [ 1.97  0.91]\n",
            " [ 0.68 -0.71]\n",
            " [-1.5   0.36]\n",
            " [ 0.78 -1.35]\n",
            " [ 0.38 -0.13]\n",
            " [-1.    0.42]\n",
            " [-0.01 -0.31]\n",
            " [-1.2   0.42]\n",
            " [-0.9  -1.21]\n",
            " [-0.11  0.04]\n",
            " [-1.6  -0.42]\n",
            " [ 0.98 -1.  ]\n",
            " [ 1.08 -1.21]\n",
            " [-0.01 -0.13]\n",
            " [-1.1  -1.52]\n",
            " [ 0.78 -1.21]\n",
            " [ 0.98  2.07]\n",
            " [-1.2  -1.52]\n",
            " [-0.31  0.79]\n",
            " [ 0.09 -0.31]\n",
            " [-1.4  -1.23]\n",
            " [-0.61 -1.5 ]\n",
            " [ 0.78  0.53]\n",
            " [-0.31 -0.34]\n",
            " [ 1.77 -0.28]\n",
            " [ 0.88 -1.03]\n",
            " [ 0.19  0.07]\n",
            " [-0.61  0.88]\n",
            " [-1.89 -1.41]\n",
            " [-1.3   0.59]\n",
            " [-0.31  0.53]\n",
            " [-1.   -1.09]\n",
            " [ 1.18 -1.44]\n",
            " [ 0.19 -0.31]\n",
            " [ 1.18 -0.74]\n",
            " [-0.31  0.07]\n",
            " [ 0.19  2.1 ]\n",
            " [ 0.78 -1.09]\n",
            " [ 0.09  0.04]\n",
            " [-1.8   0.13]\n",
            " [-0.9   0.16]\n",
            " [-0.71  0.19]\n",
            " [ 0.88 -1.29]\n",
            " [ 0.19 -0.25]\n",
            " [-0.41  1.23]\n",
            " [-0.01  0.3 ]\n",
            " [ 0.38  0.16]\n",
            " [ 0.88 -0.65]\n",
            " [ 0.09  0.16]\n",
            " [-1.89 -1.29]\n",
            " [-0.11  0.3 ]\n",
            " [-0.21 -0.28]\n",
            " [ 0.28 -0.51]\n",
            " [-0.21  1.61]\n",
            " [ 0.98 -1.18]\n",
            " [-0.21  1.64]\n",
            " [ 1.27  1.87]\n",
            " [-1.1  -0.36]\n",
            " [-0.01  0.04]\n",
            " [ 0.09 -0.25]\n",
            " [-1.6  -1.23]\n",
            " [-0.51 -0.28]\n",
            " [ 0.98  0.13]\n",
            " [ 1.97 -1.35]\n",
            " [ 1.47  0.07]\n",
            " [-0.61  1.37]\n",
            " [ 1.57  0.01]\n",
            " [-0.8   0.3 ]\n",
            " [ 1.97  0.74]\n",
            " [-1.2  -0.51]\n",
            " [ 0.68  0.27]\n",
            " [-1.4  -0.42]\n",
            " [ 0.19  0.16]\n",
            " [-0.51 -1.21]\n",
            " [ 0.58  2.01]\n",
            " [-1.6  -1.5 ]\n",
            " [-0.51 -0.54]\n",
            " [ 0.48  1.84]\n",
            " [-1.4  -1.09]\n",
            " [ 0.78 -1.38]\n",
            " [-0.31 -0.42]\n",
            " [ 1.57  1.  ]\n",
            " [ 0.98  1.43]\n",
            " [-0.31 -0.48]\n",
            " [-0.11  2.16]\n",
            " [-1.5  -0.1 ]\n",
            " [-0.11  1.95]\n",
            " [-0.71 -0.34]\n",
            " [-0.51 -0.83]\n",
            " [ 0.68 -1.38]\n",
            " [-0.8  -1.58]\n",
            " [-1.89 -1.47]\n",
            " [ 1.08  0.13]\n",
            " [ 0.09  1.52]\n",
            " [-0.31  0.1 ]\n",
            " [ 0.09  0.04]\n",
            " [-1.4  -1.35]\n",
            " [ 0.28  0.07]\n",
            " [-0.9   0.39]\n",
            " [ 1.57 -1.26]\n",
            " [-0.31 -0.74]\n",
            " [-0.11  0.16]\n",
            " [-0.9  -0.65]\n",
            " [-0.71 -0.05]\n",
            " [ 0.38 -0.45]\n",
            " [-0.8   1.9 ]\n",
            " [ 1.37  1.29]\n",
            " [ 1.18 -0.97]\n",
            " [ 1.77  1.84]\n",
            " [-0.9  -0.25]\n",
            " [-0.8   0.56]\n",
            " [-1.2  -1.55]\n",
            " [-0.51 -1.12]\n",
            " [ 0.28  0.07]\n",
            " [-0.21 -1.06]\n",
            " [ 1.67  1.61]\n",
            " [ 0.98  1.78]\n",
            " [ 0.28  0.04]\n",
            " [-0.8  -0.22]\n",
            " [-0.11  0.07]\n",
            " [ 0.28 -0.19]\n",
            " [ 1.97 -0.65]\n",
            " [-0.8   1.35]\n",
            " [-1.8  -0.6 ]\n",
            " [-0.11  0.13]\n",
            " [ 0.28 -0.31]\n",
            " [ 1.08  0.56]\n",
            " [-1.    0.27]\n",
            " [ 1.47  0.36]\n",
            " [ 0.19 -0.36]\n",
            " [ 2.17 -1.03]\n",
            " [-0.31  1.11]\n",
            " [-1.7   0.07]\n",
            " [-0.01  0.04]\n",
            " [ 0.09  1.06]\n",
            " [-0.11 -0.36]\n",
            " [-1.2   0.07]\n",
            " [-0.31 -1.35]\n",
            " [ 1.57  1.11]\n",
            " [-0.8  -1.52]\n",
            " [ 0.09  1.87]\n",
            " [-0.9  -0.77]\n",
            " [-0.51 -0.77]\n",
            " [-0.31 -0.92]\n",
            " [ 0.28 -0.71]\n",
            " [ 0.28  0.07]\n",
            " [ 0.09  1.87]\n",
            " [-1.1   1.95]\n",
            " [-1.7  -1.55]\n",
            " [-1.2  -1.09]\n",
            " [-0.71 -0.1 ]\n",
            " [ 0.09  0.1 ]\n",
            " [ 0.28  0.27]\n",
            " [ 0.88 -0.57]\n",
            " [ 0.28 -1.15]\n",
            " [-0.11  0.68]\n",
            " [ 2.17 -0.68]\n",
            " [-1.3  -1.38]\n",
            " [-1.   -0.94]\n",
            " [-0.01 -0.42]\n",
            " [-0.21 -0.45]\n",
            " [-1.8  -0.97]\n",
            " [ 1.77  1.  ]\n",
            " [ 0.19 -0.36]\n",
            " [ 0.38  1.11]\n",
            " [-1.8  -1.35]\n",
            " [ 0.19 -0.13]\n",
            " [ 0.88 -1.44]\n",
            " [-1.99  0.48]\n",
            " [-0.31  0.27]\n",
            " [ 1.87 -1.06]\n",
            " [-0.41  0.07]\n",
            " [ 1.08 -0.89]\n",
            " [-1.1  -1.12]\n",
            " [-1.89  0.01]\n",
            " [ 0.09  0.27]\n",
            " [-1.2   0.33]\n",
            " [-1.3   0.3 ]\n",
            " [-1.    0.45]\n",
            " [ 1.67 -0.89]\n",
            " [ 1.18  0.53]\n",
            " [ 1.08  0.53]\n",
            " [ 1.37  2.33]\n",
            " [-0.31 -0.13]\n",
            " [ 0.38 -0.45]\n",
            " [-0.41 -0.77]\n",
            " [-0.11 -0.51]\n",
            " [ 0.98 -1.15]\n",
            " [-0.9  -0.77]\n",
            " [-0.21 -0.51]\n",
            " [-1.1  -0.45]\n",
            " [-1.2   1.4 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E--Vc-xXF-Si"
      },
      "source": [
        "# Training the Classification model on the whole dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqr2wko6BWjL",
        "outputId": "5346585d-4a5e-4a42-9af8-145e9b2716c2"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "classifier = DecisionTreeClassifier(random_state=0, criterion = 'entropy', max_depth=10)\n",
        "\n",
        "\n",
        "classifier.fit(X_train, y_train)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n",
              "                       max_depth=10, max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=0, splitter='best')"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYeLkrJ3dC7b"
      },
      "source": [
        "# Predicting a new result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DgBGtecC_EY",
        "outputId": "193fb1e7-7ed9-44d9-a893-d6fdfd2cd2da"
      },
      "source": [
        "print(X_test[[5]])"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.81 -1.54]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MrW_BQlClKp",
        "outputId": "dbefdbb9-9932-439a-b3a2-5ea0aba64e4c"
      },
      "source": [
        "classifier.predict(X_test[[7]])"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKHSNFx0F4Tc"
      },
      "source": [
        "### Predicting the TEst set results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DoU_1xKJF6zN",
        "outputId": "e5d994be-27ad-430a-e901-382d66788142"
      },
      "source": [
        "y_pred = classifier.predict(X_test)\n",
        "np.set_printoptions(precision=2)\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [1 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 1]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 1]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdsL_YmQ824X"
      },
      "source": [
        "### Making the Confusion Matrix\n",
        "\n",
        "Confusion Matrix shows how many mistakes the model has made"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8Tu1F4pHO4u",
        "outputId": "07ba24c3-e6f3-40d1-c8bb-5b322fbfef8b"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "cm = confusion_matrix(y_test,y_pred)\n",
        "print(cm)\n",
        "# [[Correct Incorrect] \n",
        "#  [Incorrect Correct]]\n",
        "acc = accuracy_score(y_test,y_pred)\n",
        "print(acc)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[63  5]\n",
            " [ 2 30]]\n",
            "0.93\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YoK01o-4I0sJ"
      },
      "source": [
        "### Visualising the Training set results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JVtlEKnI2yj"
      },
      "source": [
        "from matplotlib.colors import ListedColormap\n",
        "X_set, y_set = sc.inverse_transform(X_train), y_train\n",
        "X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 10 , stop = X_set[:, 0].max() + 10, step = 0.25), \n",
        "                     np.arange(start = X_set[:, 1].min() - 1000, stop = X_set[:, 1].max() + 1000, step = 0.25))\n",
        "plt.contourf(X1, X2, classifier.predict(sc.transform(np.array([X1.ravel(), X2.ravel()]).T)).reshape(X1.shape),\n",
        "             alpha = 0.75, cmap = ListedColormap(('red', 'green')))\n",
        "plt.xlim(X1.min(), X1.max())\n",
        "plt.ylim(X2.min(), X2.max())\n",
        "for i,j in enumerate(np.unique(y_set)):\n",
        "  plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1], c = ListedColormap(('red','green'))(i), label = j)\n",
        "plt.title('Logistic Regression (Training set)')\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Estimated Salary')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zxmyAhY85gw"
      },
      "source": [
        "### Visualising the Test set results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2bPJua5Iyt9"
      },
      "source": [
        "from matplotlib.colors import ListedColormap\n",
        "X_set, y_set = sc.inverse_transform(X_test), y_test\n",
        "X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 10 , stop = X_set[:, 0].max() + 10, step = 0.35), \n",
        "                     np.arange(start = X_set[:, 1].min() - 1000, stop = X_set[:, 1].max() + 1000, step = 0.35))\n",
        "plt.contourf(X1, X2, classifier.predict(sc.transform(np.array([X1.ravel(), X2.ravel()]).T)).reshape(X1.shape),\n",
        "             alpha = 0.75, cmap = ListedColormap(('red', 'green')))\n",
        "plt.xlim(X1.min(), X1.max())\n",
        "plt.ylim(X2.min(), X2.max())\n",
        "for i,j in enumerate(np.unique(y_set)):\n",
        "  plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1], c = ListedColormap(('red','green'))(i), label = j)\n",
        "plt.title('Logistic Regression (Test set)')\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Estimated Salary')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}